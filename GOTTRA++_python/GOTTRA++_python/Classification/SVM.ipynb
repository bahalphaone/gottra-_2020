{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC STOPWORDS OCCURENCES/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv('../Ressources/separated_data/scenarii_training_text.csv', encoding=\"ISO-8859-1\")\n",
    "train_tags = pd.read_csv('../Ressources/separated_data/scenarii_training_tags.csv', encoding=\"ISO-8859-1\")\n",
    "test_text = pd.read_csv('../Ressources/separated_data/scenarii_testing_text.csv', encoding=\"ISO-8859-1\")\n",
    "test_tags = pd.read_csv('../Ressources/separated_data/scenarii_testing_tags.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "train_text = train_text[train_text.columns[0]]\n",
    "train_tags = train_tags[train_tags.columns[0]]\n",
    "test_text = test_text[test_text.columns[0]]\n",
    "test_tags = test_tags[test_tags.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9342449225160298\n",
      "Recall: 0.9504956462729549\n",
      "F measure: 0.9421355566825083\n"
     ]
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', svm.SVC(kernel='linear', C=1))])\n",
    "text_clf_svm.fit(train_text, train_tags)\n",
    "predicted_svm = text_clf_svm.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted_svm, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Ressources/scenarii.csv\", encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "tags = df['tag']\n",
    "data = CountVectorizer().fit_transform(df['texte']).toarray()\n",
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9105579858100141\n",
      "0.8987427718480351\n",
      "0.9380797210238289\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET SANS STOPWORDS  OCCURENCES/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.937981957603639\n",
      "Recall: 0.9628161322871076\n",
      "F measure: 0.9498376975621559\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle SVM pour les données sans stopwords.\n",
    "'''\n",
    "stopwords_fr = stopwords.words('french')\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words = stopwords_fr)),\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', svm.SVC(kernel='linear', C=1))])\n",
    "\n",
    "text_clf_svm.fit(train_text, train_tags)\n",
    "\n",
    "#enregistrer le modèle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'Models/svm_bow_without_stopwords.pkl'\n",
    "joblib.dump(text_clf_svm, filename) #text_clf est le classifieur à enregistrer\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(test_text)\n",
    "\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted_svm, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Ressources/scenarii.csv\", encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "tags = df['tag']\n",
    "data = CountVectorizer(stop_words = stopwords_fr).fit_transform(df['texte']).toarray()\n",
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111913354572934\n",
      "0.9020158963843175\n",
      "0.9371963677330749\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC VERBES OCCURENCES/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv(\"../Ressources/data_verbs_only/training_matrix_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "train_tags = pd.read_csv(\"../Ressources/data_verbs_only/training_tags_with_verbs.csv\", \n",
    "                         encoding=\"ISO-8859-1\", sep=\",\", header = None)  \n",
    "test_text = pd.read_csv(\"../Ressources/data_verbs_only/testing_text_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)\n",
    "test_tags = pd.read_csv(\"../Ressources/data_verbs_only/testing_tags_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7894495762453508\n",
      "Recall: 0.7408789846044828\n",
      "F measure: 0.7390533276050665\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle SVM pour les données avec les verbes uniquement.\n",
    "'''\n",
    "text_clf_svm = Pipeline([\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', svm.SVC(kernel='linear', C=1))])\n",
    "text_clf_svm.fit(train_text, train_tags)\n",
    "predicted_svm = text_clf_svm.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted_svm, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Ressources/data_verbs_only/all_data_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "\n",
    "tags = pd.read_csv(\"../Ressources/data_verbs_only/all_tags.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7690194942453921\n",
      "0.7780153180153182\n",
      "0.7872809942754716\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle SVM pour les données avec les verbes uniquemet en utilisant la cross validation.\n",
    "'''\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scoring = {'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC VERBES D'ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv(\"../Ressources/data_action_verbs_only/training_matrix_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "train_tags = pd.read_csv(\"../Ressources/data_action_verbs_only/training_tags_with_action_verbs.csv\", \n",
    "                         encoding=\"ISO-8859-1\", sep=\",\", header = None)  \n",
    "test_text = pd.read_csv(\"../Ressources/data_action_verbs_only/testing_text_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)\n",
    "test_tags = pd.read_csv(\"../Ressources/data_action_verbs_only/testing_tags_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7178591305850834\n",
      "Recall: 0.491617727727171\n",
      "F measure: 0.5116184982675399\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle SVM pour les données avec les verbes d'action uniquement.\n",
    "'''\n",
    "text_clf_svm = Pipeline([\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', svm.SVC(kernel='linear', C=1))])\n",
    "text_clf_svm.fit(train_text, train_tags)\n",
    "predicted_svm = text_clf_svm.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted_svm, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted_svm, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Ressources/data_action_verbs_only/all_data_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "\n",
    "tags = pd.read_csv(\"../Ressources/data_action_verbs_only/all_tags.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "\n",
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5063782415736953\n",
      "0.48783348676301397\n",
      "0.7602583097208973\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle SVM pour les données avec les verbes d'action uniquemet en utilisant la cross validation.\n",
    "'''\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring='f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
