{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC STOPWORDS OCCURENCES/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv('../Ressources/separated_data/scenarii_training_text_sans_chiffres.csv', encoding=\"ISO-8859-1\", header = None)\n",
    "train_tags = pd.read_csv('../Ressources/separated_data/scenarii_training_tags_sans_chiffres.csv', encoding=\"ISO-8859-1\", header = None)\n",
    "test_text = pd.read_csv('../Ressources/separated_data/scenarii_testing_text_sans_chiffres.csv', encoding=\"ISO-8859-1\", header = None)\n",
    "test_tags = pd.read_csv('../Ressources/separated_data/scenarii_testing_tags_sans_chiffres.csv', encoding=\"ISO-8859-1\", header = None)\n",
    "\n",
    "train_text = train_text[train_text.columns[0]]\n",
    "train_tags = train_tags[train_tags.columns[0]]\n",
    "test_text = test_text[test_text.columns[0]]\n",
    "test_tags = test_tags[test_tags.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7245898769676968\n",
      "Recall: 0.47185381800906523\n",
      "F measure: 0.4735791673931516\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_text, train_tags)\n",
    "predicted = text_clf.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Ressources/scenarii.csv\", encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "tags = df['tag']\n",
    "data = CountVectorizer().fit_transform(df['texte']).toarray()\n",
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594572949697851\n",
      "0.5492801993328309\n",
      "0.8668031953683976\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET SANS STOPWORDS OCCURENCES/TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8771562113217379\n",
      "Recall: 0.48858162431867636\n",
      "F measure: 0.49771607701991866\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle Naive Bayes pour les données sans stopwords.\n",
    "'''\n",
    "stopwords_fr = stopwords.words('french')\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = stopwords_fr)),\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf.fit(train_text, train_tags)\n",
    "predicted = text_clf.predict(test_text)\n",
    "\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Ressources/scenarii.csv\", encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "tags = df['tag']\n",
    "data = CountVectorizer(stop_words = stopwords_fr).fit_transform(df['texte']).toarray()\n",
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232842369298792\n",
      "0.5765270986323617\n",
      "0.8538589573126124\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC VERBES OCCURENCES/TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv(\"../Ressources/data_verbs_only/training_matrix_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "train_tags = pd.read_csv(\"../Ressources/data_verbs_only/training_tags_with_verbs.csv\", \n",
    "                         encoding=\"ISO-8859-1\", sep=\",\", header = None)  \n",
    "test_text = pd.read_csv(\"../Ressources/data_verbs_only/testing_text_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)\n",
    "test_tags = pd.read_csv(\"../Ressources/data_verbs_only/testing_tags_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6609297725024728\n",
      "Recall: 0.31890965550653677\n",
      "F measure: 0.3425557889030485\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle Naive Bayes pour les données avec les verbes uniquement.\n",
    "'''\n",
    "text_clf = Pipeline([\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_text, train_tags)\n",
    "predicted = text_clf.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Ressources/data_verbs_only/all_data_with_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\";\", header=0)\n",
    "\n",
    "tags = pd.read_csv(\"../Ressources/data_verbs_only/all_tags.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "data = TfidfTransformer().fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3546348255076156\n",
      "0.3241959013332787\n",
      "0.6627837220329535\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle Naive Bayes pour les données avec les verbes uniquemet en utilisant la cross validation.\n",
    "'''\n",
    "clf = MultinomialNB()\n",
    "scoring = {'prec': 'average_precision', \n",
    "           'recall': 'recall',\n",
    "           'f1_macro': 'f1_macro'}\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET AVEC VERBES D'ACTION OCCURENCES/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv(\"../Ressources/data_action_verbs_only/training_matrix_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "train_tags = pd.read_csv(\"../Ressources/data_action_verbs_only/training_tags_with_action_verbs.csv\", \n",
    "                         encoding=\"ISO-8859-1\", sep=\",\", header = None)  \n",
    "test_text = pd.read_csv(\"../Ressources/data_action_verbs_only/testing_text_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)\n",
    "test_tags = pd.read_csv(\"../Ressources/data_action_verbs_only/testing_tags_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6834972911320216\n",
      "Recall: 0.31998003785834367\n",
      "F measure: 0.34045399668098647\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle Naive Bayes pour les données avec les verbes d'action uniquement.\n",
    "'''\n",
    "text_clf = Pipeline([\n",
    "                         #Commenter cette ligne pour avoir les occurences, et enlever le commentaire pour avoir les scores TF-IDF\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_text, train_tags)\n",
    "predicted = text_clf.predict(test_text)\n",
    "print(\"Precision: \" + str(precision_score(test_tags, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(test_tags, predicted, average='macro')))\n",
    "print(\"F measure: \" + str(f1_score(test_tags, predicted, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Ressources/data_action_verbs_only/all_data_with_action_verbs.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)\n",
    "\n",
    "tags = pd.read_csv(\"../Ressources/data_action_verbs_only/all_tags.csv\", \n",
    "                   encoding=\"ISO-8859-1\", sep=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4748317554476883\n",
      "0.4200975735534166\n",
      "0.6840339766891782\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Construction du modèle Naive Bayes pour les données avec les verbes d'action uniquemet en utilisant la cross validation.\n",
    "'''\n",
    "clf = MultinomialNB()\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring='f1_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'recall_macro')\n",
    "print(np.mean(scores))\n",
    "scores = cross_val_score(clf, data, tags, cv=5, scoring = 'precision_macro')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
